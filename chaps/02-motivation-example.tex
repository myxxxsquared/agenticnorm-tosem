\section{Motivating Example}

\input{floats/02-01-motivation-example}

To illustrate the challenges of detecting anomalies from API logs, we examine a case from the \trainticket dataset~\cite{trainticketsystem} involving a compromised ticket refund process. In a normal workflow, refund requires two steps.
First, the user retrieves a list of refundable tickets. This list is displayed on the frontend, allowing the user to select which ticket to refund.
Second, the user selects one of these tickets and submits a refund request.

APIs serve as the communication interface between frontend and backend components, typically defined by a request path and a payload format.
Logs record the actual data exchanged through these APIs, usually including the request path and a request body and a response body.

Figure~\ref{fig:motivating_example} shows a simplified version of the relevant log entries, while the full logs are available in our anonymous artifact~\cite{agenticnorm-website}.
In our example, when the user retrieves refundable tickets, the frontend calls the \texttt{/api/v1/queryOrders} (abbreviated as  \texttt{queryOrders}) API (\ding{192} step in Figure~\ref{fig:motivating_example}), which returns a list of ticket orders.
When the user selects a ticket to refund, the frontend calls the \texttt{/api/v1/refund} (abbreviated as \texttt{refund}) API (\ding{193} step in Figure~\ref{fig:motivating_example}).
During invoking the \texttt{queryOrders} API, the backend returns a list of refundable tickets in the \texttt{results} field, each identified by a unique \texttt{id}.
When invoking the \texttt{refund} API, the frontend provides an \texttt{orderId} in the request arguments to specify which ticket to refund.

In normal operation, the frontend only shows tickets that can be legitimately refunded, and the user can only select from this list.
So the \texttt{orderId} provided in the \texttt{refund} request must match one of the \texttt{id} values returned by the preceding \texttt{queryOrders} call.
So there is a consistency constraint between these two APIs:
\begin{quote}
    \texttt{refund.arguments.orderId} must appear in \texttt{queryOrders.results[].id}.
\end{quote}

However, because frontend code executes entirely on the client side, a malicious user can tamper with browser data and forge unauthorized requests.
For example, the attacker may replace the valid \texttt{orderId} with an arbitrary identifier not returned by \texttt{queryOrders} (e.g., \texttt{418ea03c}).
This manipulation allows the attacker to refund a ticket they do not own or to repeat a refund that should not be permitted.
Such behavior can cause duplicate refunds and financial losses, creating significant risks to system security and integrity.

\subsection{Existing Approaches}
Existing log-based anomaly detection methods fall into two categories:
(1) \textbf{Model-learning-based approaches}, which learn embeddings or features from normal and attack logs to classify anomalies; and
(2) \textbf{Rule-learning-based approaches}, which derive semantic constraints from logs and flag violations.

Model-learning-based approaches struggle in this scenario because normal and attack logs differ in only a few fields, making them nearly indistinguishable in embedding space.
Furthermore, anomalies may be buried within long sequences of interleaved events, diluting the anomaly signal.

The rule-learning-based approach WebNorm~\cite{liao2024detecting} addresses this limitation by leveraging LLMs to infer semantic constraints from logs. For instance, it can derive constraints such as requiring \texttt{arguments.orderId} to be a valid UUID. By mapping code-level data flows to log fields and validating them as constraints, WebNorm can flag any violations as anomalies. However, due to its prompt design and the lengthy, nested nature of input logs, the authors acknowledge that WebNorm fails to capture the some cross-API constraint illustrated in Figure~\ref{fig:motivating_example}, leaving such attacks undetected~\cite{liao2024detecting}. Despite its strengths, WebNorm still suffers from three key limitations:

\input{floats/02-04-number-of-tokens-in-input}

\input{floats/02-05-webnorm-prompt}

\begin{itemize}
    \item \textbf{Dependence on program analysis and source code}: WebNorm requires access to and instrumentation of frontend/backend code, which is costly, fragile under rapid iteration, and infeasible for closed-source or third-party systems.
    \item \textbf{Reliance on heavyweight proprietary LLMs}: constraint synthesis depends on remote, proprietary LLMs, leading to cost and privacy risks. However, if directly replaced with a local deployable model, the long and nested logs often exceed the ability of small models, reducing effectiveness. Table~\ref{tab:webnorm-input-tokens} shows the number of input tokens for two datasets. The mean input length for \trainticket is $2.40 \times 10^5$ tokens, far exceeding the context window of lightweight models due to very lengthy logs. Even for \nicefish, which has shorter logs, the mean input length is $1.50 \times 10^4$ tokens, still too long for lightweight models.
    \item \textbf{Prompt sensitivity}: correct constraints often appear only with carefully engineered prompts, making the process labor-intensive, project-specific, and difficult to generalize. Figure~\ref{fig:webnorm-prompt} illustrates the direct mapping between prompt instructions and generated constraints. The generated constraints strictly adhere to the specified prompt and are limited to the constraint types explicitly mentioned. As a result, WebNorm may miss important constraints not covered by the prompt, leading to undetected anomalies.
\end{itemize}

\subsection{Our Approach}

We aim to preserve WebNorm’s strength in capturing \emph{consistency constraints} while addressing its limitations.
Unlike WebNorm, our approach relies only on logs (without program analysis), operates primarily with lightweight, locally deployable LLMs, and mitigates prompt sensitivity by automatically refining prompts through generated attack logs.

\lighttechname directly infers constraints from raw logs. \lighttechname discovers inter-API relationships using frequency-based analysis of co-occurring API logs and derives constraints. To handle long and nested logs, \lighttechname employs \textbf{Field Clustering} to reduce input length while retaining meaningful comparisons. To mitigate prompt sensitivity, \lighttechname introduces \textbf{Prompt Refinement via Generated Attacks}, to iteratively improve prompts using adversarially generated logs that reveal missing constraints.

\paragraph{Field Clustering}
To efficiently adapt logs for lightweight models, \lighttechname expands each log entity into individual fields and then groups comparable ones into clusters.
Figure~\ref{fig:motivating_example_clustering} illustrates this process. Each cluster is given as a separate input to the LLM, ensuring that related fields are explicitly compared while avoiding unnecessary context.

\input{floats/02-02-motivation-example-clustering}

\paragraph{Prompt Refinement via Generated Attacks}
Figure~\ref{fig:motivating_example_prompt} (left) shows the original WebNorm prompt, which depends on handcrafted instructions and examples and cannot cover all possible constraints.
Figure~\ref{fig:motivating_example_prompt} (middle) shows the refined prompt in \lighttechname after several iterations of attack generation and prompt refinement.
The refined prompt includes more explicit instructions, e.g., specifying that fields with similar names should be compared.
Figure~\ref{fig:motivating_example_prompt} (right) shows the generated constraints that correctly capture the necessary field-level dependencies, by one-of the instructions in refined prompt, which WebNorm’s prompt failed to identify.

\input{floats/02-03-motivation-example-prompt}

