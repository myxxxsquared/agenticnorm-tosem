
% {\color{red}{TODOS: 1) replace all "attack" to abnormal. 2) replace invaraints to constraints 3) place novelty to adversal learning. 4) add more examples. 5) add more details in method}}

\section{Introduction}

Web applications play a critical role in modern infrastructures, supporting domains such as finance~\cite{feyen2021fintech,vukovic2025ai}, e-commerce~\cite{rahman2022revolutionizing}, and healthcare~\cite{lazakidou2009web}. Their reliability and security are of paramount importance. Unfortunately, web frontends are inherently manipulable: attackers can alter client-side code or parameters to bypass validations, tamper with workflows, or inject attack behaviors.  

In principle, backend applications implement authorization checks and other safeguards to prevent such manipulations. However, because attack behaviors are often difficult to exhaustively covered through conventional frontend testing, certain attack actions may escape detection by the backend, leaving exploitable vulnerabilities.  
To mitigate such risks, log analysis has become an effective defense mechanism. Logs in web systems typically record detailed interactions between clients and servers, including API calls, request parameters, and response statuses. Analyzing these logs enables the identification of attack interaction patterns that may signal security threats~\cite{yen2013beehive,alam2019framework}. Existing log analysis approaches typically learn models from logs to detect anomalies. These \emph{model-learning-based approaches} fall into two main paradigms: (1) training neural network models (such as deep learning classifiers) from normal logs to predict anomalies~\cite{acharya2007mining,lorenzoli2008automatic,walkinshaw2008inferring,pradel2009automatic,beschastnikh2011leveraging,krka2014automatic,breier2015anomaly,amar2018using,rufino2020improving,stocco2020towards,kang2019spatiotemporal,njoku2025kernel,wu2023effectiveness,lupton2021literature,alam2019framework,schneider2010synoptic,du2017deeplog,brown2018recurrent}, and (2) directly using large language models (LLMs) to judge whether logs contain anomalies.

While effective in many scenarios, these model-learning-based approaches suffer from significant limitations. First, they have limited interpretability: the output is often a binary decision without clear explanations of the underlying cause. Given the large volume of logs in practice, even a small false positive rate can result in overwhelming numbers of alerts, complicating deployment. Moreover, these methods often struggle to detect subtle anomalies~\cite{no2023rapid}; when malicious modifications closely mimic normal behaviors, the models tend to misclassify them, leading to missed detections.  

To address these limitations, our prior work WebNorm~\cite{liao2024detecting} proposed a \emph{rule-learning-based approach} that extracts explicit logical constraints from logs for anomaly detection. Unlike model-learning approaches, WebNorm combines program analysis and LLM inference: it first analyzes source code to identify how data flow across APIs, and then employs manually crafted prompts to guide the LLM in generating explicit constraints. For example, WebNorm can infer constraints like API1's input field A should match API2's output field B. This provides strong interpretability, as a violated constraint points to the concrete reason for detection. However, despite these advantages, WebNorm faces three key limitations that hinder its broader applicability and practical deployment:

\begin{itemize}
    \item \textbf{Dependence on program analysis and source code}: it requires access to frontend/backend code and derives event relationships using program analysis by analyzing how data flow across API calls and execution traces, which is costly for deployment in new systems, and infeasible for closed-source or third-party components.
    \item \textbf{Reliance on heavyweight proprietary LLMs}: constraint confirmation and synthesis depend on heavyweight proprietary models, which introduce latency, cost, and compliance/privacy risks. Furthermore, real logs are long and deeply nested, often exceeding the context windows of lightweight models and forcing reliance on heavyweight remote services.  
    \item \textbf{Prompt sensitivity}: generating correct constraints often requires carefully crafted prompts. This results in project-specific manual engineering with poor transferability and unstable outcomes.  
\end{itemize}  

In this paper, we present \lighttechname, a significant extension of WebNorm that addresses these limitations through a lightweight anomaly detection framework. Building upon WebNorm's foundation of constraint-based anomaly detection, \lighttechname retains the interpretability of rule-based methods while removing the barriers to deployment. Our design extends WebNorm with three key innovations that directly address the above challenges. First, instead of relying on program analysis, we operate entirely on logs and uncover inter-API relationships through frequency-based analysis of co-occurring calls, deriving constraints directly from runtime behaviors without requiring source code access. Second, to cope with the long and nested nature of real-world logs, we introduce \textbf{field clustering}, which expands nested entities into flattened fields and groups them into semantically coherent clusters. By invoking the LLM over one cluster at a time, the system significantly reduces input length while preserving meaningful comparisons, enabling lightweight models to handle large-scale logs. Third, to overcome prompt sensitivity, we employ an iterative loop of \textbf{prompt refinement via generated attacks}. Adversarial logs are synthesized to reveal missing constraints, and these counterexamples enrich the prompts with more explicit and diverse descriptions. As a result, refined prompts progressively capture a broader range of conditions, reduce noise, and improve recall without relying on manual engineering.

\lighttechname integrates these components into a novel multi-agent workflow, where agents for constraint generation, attack generation, and prompt refinement cooperate iteratively. The system thus adapts and self-improves with minimal human intervention, enabling effective and interpretable anomaly detection using only lightweight, locally deployable LLMs, eliminating WebNorm's dependence on heavyweight proprietary models.

This paper, as a significant extension of WebNorm, makes the following contributions:
\begin{itemize}
    \item We present \lighttechname, a lightweight extension of WebNorm that eliminates source code dependence by deriving semantic constraints directly from logs through frequency-based analysis, making it broadly applicable to closed-source and third-party systems without requiring program instrumentation.  
    \item We introduce field clustering to handle large-scale, deeply nested logs, enabling lightweight locally deployable LLMs to replace WebNorm's reliance on heavyweight proprietary models while maintaining effective constraint generation.  
    \item We propose a novel log-oriented prompt learning technique that leverages adversarial attack generation to iteratively refine prompts. This approach overcomes WebNorm's prompt sensitivity limitations, eliminates manual prompt engineering, and enhances stability and transferability across applications.  
    \item We implement the complete \lighttechname framework that integrates field clustering, attack generation, and prompt refinement into a novel multi-agent workflow. The source code and datasets are publicly available in our repository~\cite{agenticnorm-website}.  
    \item We conduct comprehensive and extensive experiments on two widely used benchmarks, TrainTicket and NiceFish, covering over 220k log entries and 230 attack cases with detailed ablation studies and comparative analyses. Results demonstrate that \lighttechname significantly outperforms the original WebNorm, achieving F1-scores of 0.92 and 0.85 compared to WebNorm's 0.88 and 0.75, while requiring no source code access and using only lightweight models.  
\end{itemize}
