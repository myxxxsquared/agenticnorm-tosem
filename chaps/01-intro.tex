
{\color{red}{TODOS: 1) replace all "attack" to abnormal. 2) replace invaraints to constraints 3) place novelty to adversal learning. 4) add more examples. 5) add more details in method}}

\section{Introduction}

Web applications play a critical role in modern infrastructures, supporting domains such as finance, e-commerce, and healthcare. Their reliability and security are of paramount importance. Unfortunately, web frontends are inherently manipulable: attackers can alter client-side code or parameters to bypass validations, tamper with workflows, or inject abnormal behaviors. These manipulations often manifest as subtle anomalies in backend logs, making detection both crucial and challenging. Traditional log-based anomaly detection methods, such as rule-based systems (e.g., Splunk, QRadar) and deep learning models (e.g., DeepLog, LogAnomaly, LogRobust), face three major obstacles: (1) subtle abnormalities may be indistinguishable from normal variations, (2) distribution shifts caused by evolving tamper strategies degrade model reliability, and (3) most solutions provide limited explainability, hindering root cause.

To address these limitations, recent work introduced WebNorm, an LLM-based framework that learns semantic constraints from web logs.
It detects abnormalities like the \trainticket case by learning cross-API constraints (e.g., \texttt{cancelOrder.arguments.orderId} must appear in \texttt{queryOrders.results[].id}).
While effective, \textsc{WebNorm} has three limitations:

\begin{itemize}
    \item \textbf{Program-analysis and source-code dependence}: it requires access to, and instrumentation of, frontend/backend code to align logs with code-level flows, which is costly, brittle under rapid changes, and infeasible for closed-source or third-party components.
    \item \textbf{Heavyweight LLMs}: constraint confirmation/synthesis relies on large, closed-source proprietary models, introducing latency, cost, and compliance/privacy concerns. Moreover, real logs are long and deeply nested, often exceeding the context window of compact models, further pushing deployments toward heavyweight remote models.
    \item \textbf{Prompt sensitivity}: the correct constraints often emerge only when the prompt is carefully crafted, leading to manual, project-specific prompt engineering with limited transferability and unstable results.
\end{itemize}

In this paper, we propose \lighttechname, a lightweight anomaly detection framework designed around compact, locally deployable LLMs. 
Unlike WebNorm, \lighttechname avoids program-analysis dependence, removes the need for heavyweight proprietary models, and mitigates prompt fragility through two key techniques:

\begin{itemize}
    \item \textbf{Eliminating source-code dependence.} Instead of relying on program instrumentation to build log-code mappings, \lighttechname directly learns constraints from raw logs. It discovers inter-API relationships using frequency-based analysis of co-occurring calls, and derives constraints purely from runtime behaviors, making the framework applicable even when source code is unavailable.
    \item \textbf{Field Clustering for Context Reduction.} To overcome the limitation of compact models on long and nested logs, \lighttechname expands JSON entities into flattened fields and groups them into semantically coherent clusters. Each cluster is processed independently, greatly reducing the context length while preserving meaningful comparisons. This enables lightweight models to handle large-scale logs without resorting to heavyweight remote LLMs.
    \item \textbf{Prompt Refinement via Generated Abnormals.} To address the fragility of manual prompt engineering, \lighttechname introduces an iterative loop where adversarial logs are automatically generated to expose missing constraints. These logs are then used to refine prompts, producing project-specific instructions that are stable and transferable across iterations. This process allows compact models to progressively capture more accurate and robust constraints without human-crafted prompts.
\end{itemize}

\lighttechname integrates these components into a multi-agent workflow, where agents for invariant generation, attack generation, and prompt refinement cooperate iteratively. The result is a system that adapts and self-improves without extensive human involvement.

\paragraph{Contributions.} This paper makes the following contributions:
\begin{itemize}
    \item We propose \lighttechname, a multi-agent framework for web anomaly detection that eliminates the dependency on application source code.
    \item We implement the \lighttechname framework and evaluate it on real-world benchmarks, including TrainTicket and NiceFish.  
    \item Experimental results demonstrate that \lighttechname requires less contextual information while achieving more effective anomaly detection compared to existing approaches.
\end{itemize}
