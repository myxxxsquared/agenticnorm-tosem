
% {\color{red}{TODOS: 1) replace all "attack" to abnormal. 2) replace invaraints to constraints 3) place novelty to adversal learning. 4) add more examples. 5) add more details in method}}

\section{Introduction}

Web applications play a critical role in modern infrastructures, supporting domains such as finance~\cite{feyen2021fintech,vukovic2025ai}, e-commerce~\cite{rahman2022revolutionizing}, and healthcare~\cite{lazakidou2009web}. Their reliability and security are of paramount importance. Unfortunately, web frontends are inherently manipulable: attackers can alter client-side code or parameters to bypass validations, tamper with workflows, or inject attack behaviors.  

In principle, backend applications implement authorization checks and other safeguards to prevent such manipulations. However, because attack behaviors are often difficult to exhaustively covered through conventional frontend testing, certain attack actions may escape detection by the backend, leaving exploitable vulnerabilities.  
To mitigate such risks, log analysis has become an effective defense mechanism. Logs in web systems typically record detailed interactions between clients and servers, including API calls, request parameters, and response statuses. Analyzing these logs enables the identification of attack interaction patterns that may signal security threats~\cite{yen2013beehive,alam2019framework}. Current state-of-the-art log analysis methods can be broadly classified into two categories: (1) \emph{model-learning-based approaches}, which train predictive models from normal logs and use them to detect anomalies~\cite{acharya2007mining,lorenzoli2008automatic,walkinshaw2008inferring,pradel2009automatic,beschastnikh2011leveraging,krka2014automatic,breier2015anomaly,amar2018using,rufino2020improving,stocco2020towards,kang2019spatiotemporal,njoku2025kernel,wu2023effectiveness,lupton2021literature,alam2019framework,schneider2010synoptic}, and (2) \emph{rule-learning-based approaches}, which mine logical constraints from logs and detect violations~\cite{liao2024detecting}.  

The first category, model-learning-based approaches, typically employ deep learning models to classify logs as normal or attack~\cite{du2017deeplog,brown2018recurrent}. While effective in many scenarios, these approaches suffer from limited interpretability: the output is often a binary decision without clear explanations of the underlying cause. Given the large volume of logs in practice, even a small false positive rate can result in overwhelming numbers of alerts, complicating deployment. Moreover, these methods often struggle to detect subtle anomalies~\cite{no2023rapid}; when malicious modifications closely mimic normal behaviors, the models tend to misclassify them, leading to missed detections.  

To address these limitations, rule-learning-based approaches attempt to extract explicit logical constraints from logs and use them for anomaly detection~\cite{liao2024detecting}. Existing rule-learning-based approaches, such as WebNorm~\cite{liao2024detecting}, utilizes program analysis on source code to dervie relationships between APIs and then employs LLMs to infer constraints from logs. For example, WebNorm can infer constraints like API1's input field A should match API2's output field B. Such approaches provide better interpretability, as the violated constraint reveals the concrete reason for detection. Despite its effectiveness, WebNorm suffers from three limitations:

\begin{itemize}
    \item \modifypart{\textbf{Dependence on program analysis and source code}: it requires access to frontend/backend code and derives event relationships using program analysis by analyzing how data flow across API calls and execution traces, which is costly for deployment in new systems, and infeasible for closed-source or third-party components.}
    \item \textbf{Reliance on heavyweight proprietary LLMs}: constraint confirmation and synthesis depend on heavyweight proprietary models, which introduce latency, cost, and compliance/privacy risks. Furthermore, real logs are long and deeply nested, often exceeding the context windows of lightweight models and forcing reliance on heavyweight remote services.  
    \item \textbf{Prompt sensitivity}: generating correct constraints often requires carefully crafted prompts. This results in project-specific manual engineering with poor transferability and unstable outcomes.  
\end{itemize}  

In this paper, we propose \lighttechname, a lightweight anomaly detection framework designed around lightweight, locally deployable LLMs. Unlike WebNorm, \lighttechname avoids dependence on program analysis, removes the need for heavyweight proprietary models, and mitigates prompt sensitivity.

\modifypart{To address the limitations of source-code dependence, \lighttechname operates entirely on logs, uncovering inter-API relationships through frequency-based analysis of co-occurring calls and deriving constraints directly from runtime behaviors. This design makes the framework applicable even in closed-source or third-party settings.

To address the limitations of lightweight models on long and nested logs, \lighttechname employs \textbf{field clustering}, which expands log entities into flattened fields and groups the fields into semantically comparable clusters, and for each invoking of LLM, only fields in one cluster would be included. By generateing constraints for each cluster independently, the system significantly reduces input length while retaining meaningful comparisons, enabling lightweight models to handle large-scale logs without resorting to heavyweight LLMs.

To address the limitations of prompt sensitivity, \lighttechname introduces \textbf{prompt refinement} and \textbf{attack generation}.
an iterative process where adversarial attack logs are automatically generated to expose missing constraints. These attack logs guide the refinement of prompts, enriching the prompt with more explicit and diverse constraint descriptions. As a result, each refined prompt specifies a broader range of conditions to be checked, enabling the lightweight model to generate additional project-specific constraints in subsequent process. This iterative process reduces reliance on manual prompt engineering and progressively improves recall of anomaly detection.
}

\lighttechname integrates these components into a multi-agent workflow, where agents for constraint generation, attack generation, and prompt refinement cooperate iteratively. The result is a system that adapts and self-improves with minimal human intervention.  

This paper makes the following contributions:
\modifypart{
\begin{itemize}
    \item We present \lighttechname, the first lightweight anomaly detection framework that derives constraints solely from logs, without relying on source code or program analysis. \lighttechname is independent of application implementation and can be easily applied to any web application with available logs.
    \item We propose a log-oriented prompt learning technique, which can fine-tune the performance of \lighttechname on a variety of LLMs. This approach overcomes the limitations of manually crafted prompts and enhances the stability and transferability of lightweight LLMs. To the best of our knowledge, this is the first work to employ attack generation for strengthening log-based anomaly detection.
    \item We implement \lighttechname framework, integrating field clustering, attack generation, and prompt refinement. The source code and data are publicly available in our repository~\cite{agenticnorm-website}. 
    \item Experimental results demonstrate that \lighttechname achieves state-of-the-art anomaly detection performance. Evaluations on two widely used benchmarks, TrainTicket and NiceFish, comprising over 220k log entries and 230 attack instances, show that \lighttechname attains F1-scores of 0.92 and 0.85, respectively, outperforming existing approaches (0.88 and 0.75).
\end{itemize}
}