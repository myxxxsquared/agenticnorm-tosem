
% {\color{red}{TODOS: 1) replace all "attack" to abnormal. 2) replace invaraints to constraints 3) place novelty to adversal learning. 4) add more examples. 5) add more details in method}}

\section{Introduction}

Web applications play a critical role in modern infrastructures, supporting domains such as finance~\cite{feyen2021fintech,vukovic2025ai}, e-commerce~\cite{rahman2022revolutionizing}, and healthcare~\cite{lazakidou2009web}. Their reliability and security are of paramount importance. Unfortunately, web frontends are inherently manipulable: attackers can alter client-side code or parameters to bypass validations, tamper with workflows, or inject attack behaviors.  

In principle, backend applications implement authorization checks and other safeguards to prevent such manipulations. However, because attack behaviors are often difficult to exhaustively covered through conventional frontend testing, certain attack actions may escape detection by the backend, leaving exploitable vulnerabilities.  
To mitigate such risks, log analysis has become an effective defense mechanism. Logs in web systems typically record detailed interactions between clients and servers, including API calls, request parameters, and response statuses. Analyzing these logs enables the identification of attack interaction patterns that may signal security threats~\cite{yen2013beehive,alam2019framework}. Current state-of-the-art log analysis methods can be broadly classified into two categories: (1) \emph{model-learning-based approaches}, which train predictive models from normal logs and use them to detect anomalies~\cite{acharya2007mining,lorenzoli2008automatic,walkinshaw2008inferring,pradel2009automatic,beschastnikh2011leveraging,krka2014automatic,breier2015anomaly,amar2018using,rufino2020improving,stocco2020towards,kang2019spatiotemporal,njoku2025kernel,wu2023effectiveness,lupton2021literature,alam2019framework,schneider2010synoptic}, and (2) \emph{rule-learning-based approaches}, which mine logical constraints from logs and detect violations~\cite{liao2024detecting}.  

The first category, model-learning-based approaches, typically employ deep learning models to classify logs as normal or attack~\cite{du2017deeplog,brown2018recurrent}. While effective in many scenarios, these approaches suffer from limited interpretability: the output is often a binary decision without clear explanations of the underlying cause. Given the large volume of logs in practice, even a small false positive rate can result in overwhelming numbers of alerts, complicating deployment. Moreover, these methods often struggle to detect subtle anomalies~\cite{no2023rapid}; when malicious modifications closely mimic normal behaviors, the models tend to misclassify them, leading to missed detections.  

To address these limitations, rule-learning-based approaches attempt to extract explicit logical constraints from logs and use them for anomaly detection~\cite{liao2024detecting}. Existing rule-learning-based approaches, such as WebNorm~\cite{liao2024detecting}, combine program analysis and LLM inference: they first analyze source code to identify how data flow across APIs, and then employ manually crafted prompts to guide the LLM in generating explicit constraints. For example, WebNorm can infer constraints like API1's input field A should match API2's output field B. This provides strong interpretability, as a violated constraint points to the concrete reason for detection. 

\begin{itemize}
    \item \textbf{Dependence on program analysis and source code}: it requires access to frontend/backend code and derives event relationships using program analysis by analyzing how data flow across API calls and execution traces, which is costly for deployment in new systems, and infeasible for closed-source or third-party components.
    \item \textbf{Reliance on heavyweight proprietary LLMs}: constraint confirmation and synthesis depend on heavyweight proprietary models, which introduce latency, cost, and compliance/privacy risks. Furthermore, real logs are long and deeply nested, often exceeding the context windows of lightweight models and forcing reliance on heavyweight remote services.  
    \item \textbf{Prompt sensitivity}: generating correct constraints often requires carefully crafted prompts. This results in project-specific manual engineering with poor transferability and unstable outcomes.  
\end{itemize}  

In this paper, we propose \lighttechname, a lightweight anomaly detection framework that retains the interpretability of rule-based methods while removing the barriers to deployment. Our design proceeds in three steps that directly address the above challenges. First, instead of relying on program analysis, we operate entirely on logs and uncover inter-API relationships through frequency-based analysis of co-occurring calls, deriving constraints directly from runtime behaviors. Second, to cope with the long and nested nature of real-world logs, we introduce \textbf{field clustering}, which expands nested entities into flattened fields and groups them into semantically coherent clusters. By invoking the LLM over one cluster at a time, the system significantly reduces input length while preserving meaningful comparisons, enabling lightweight models to handle large-scale logs. Third, to overcome prompt sensitivity, we employ an iterative loop of \textbf{prompt refinement via generated attacks}. Adversarial logs are synthesized to reveal missing constraints, and these counterexamples enrich the prompts with more explicit and diverse descriptions. As a result, refined prompts progressively capture a broader range of conditions, reduce noise, and improve recall without relying on manual engineering.

\lighttechname integrates these components into a multi-agent workflow, where agents for constraint generation, attack generation, and prompt refinement cooperate iteratively. The system thus adapts and self-improves with minimal human intervention, enabling effective and interpretable anomaly detection using only lightweight, locally deployable LLMs.  

This paper makes the following contributions:
\begin{itemize}
    \item We introduce \lighttechname, the first lightweight anomaly detection framework that derives semantic constraints directly from logs without relying on source code or program analysis, making it broadly applicable to closed-source and third-party systems.  
    \item We propose a log-oriented prompt learning technique that leverages adversarial attack generation to iteratively refine prompts. This approach overcomes the limitations of manually crafted prompts, enhances stability across applications, and improves the transferability of lightweight LLMs.  
    \item We implement \lighttechname framework that integrates field clustering, attack generation, and prompt refinement into a multi-agent workflow. The source code and datasets are publicly available in our repository~\cite{agenticnorm-website}.  
    \item We conduct extensive experiments on two widely used benchmarks, TrainTicket and NiceFish, covering over 220k log entries and 230 attack cases. Results show that \lighttechname achieves state-of-the-art performance, attaining F1-scores of 0.92 and 0.85, and outperforming prior approaches such as WebNorm (0.88 and 0.75).  
\end{itemize}
